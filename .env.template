# .env file template for Ash
# Copy this file to .env and fill in your actual values

# =============================================================================
# GLOBAL CONFIGURATION
# =============================================================================
GLOBAL_CLAUDE_API_KEY=/run/secrets/claude_api_key
GLOBAL_SESSION_TOKEN=/run/secrets/session_token
GLOBAL_REDIS_PASSWORD=/run/secrets/redis
GLOBAL_HUGGINGFACE_TOKEN=/run/secrets/huggingface
GLOBAL_CLAUDE_MODEL=claude-sonnet-4-20250514
GLOBAL_PYTHONUNBUFFERED=1
GLOBAL_LOG_LEVEL=INFO
GLOBAL_ENABLE_DEBUG_MODE=false
GLOBAL_BOT_API_HOST=172.20.0.10
GLOBAL_BOT_API_PORT=8882
GLOBAL_BOT_API_URL=http://172.20.0.10:8882
GLOBAL_NLP_API_HOST=172.20.0.11
GLOBAL_NLP_API_PORT=8881
GLOBAL_NLP_API_URL=http://172.20.0.11:8881
GLOBAL_DASH_API_PORT=8883
GLOBAL_THRASH_API_PORT=8884
GLOBAL_REQUEST_TIMEOUT=30
GLOBAL_ENABLE_LEARNING_SYSTEM=true
GLOBAL_ALLOWED_IPS=10.20.30.0/24,172.20.0.0/16,127.0.0.1,::1
GLOBAL_ENABLE_CORS=true

# =============================================================================
# ASH-BOT CONFIGURATION
# =============================================================================
# =============================================================================
# Discord Setup
# =============================================================================
BOT_DISCORD_TOKEN=/run/secrets/discord_token
BOT_GUILD_ID=
BOT_RESOURCES_CHANNEL_ID=
BOT_CRISIS_RESPONSE_CHANNEL_ID=
BOT_ALLOWED_CHANNELS=
BOT_STAFF_PING_USER=
BOT_CRISIS_RESPONSE_ROLE_ID=
BOT_RESOURCES_CHANNEL_NAME=resources
BOT_CRISIS_RESPONSE_ROLE_NAME=CrisisResponse
BOT_STAFF_PING_NAME=StaffName

# =============================================================================
# Learning Setup
# =============================================================================
BOT_LEARNING_CONFIDENCE_THRESHOLD=0.6
BOT_MAX_LEARNING_ADJUSTMENTS_PER_DAY=50
BOT_MAX_DAILY_CALLS=1000
BOT_RATE_LIMIT_PER_USER=10

# =============================================================================
# Conversation Settings
# =============================================================================
BOT_CONVERSATION_REQUIRES_MENTION=true
BOT_CONVERSATION_TRIGGER_PHRASES=ash,hey ash,ash help,@ash
BOT_CONVERSATION_ALLOW_STARTERS=true
BOT_CONVERSATION_SETUP_INSTRUCTIONS=true
BOT_CRISIS_OVERRIDE_LEVELS=medium,high
BOT_CONVERSATION_LOG_ATTEMPTS=true
BOT_CONVERSATION_TIMEOUT=300

# =============================================================================
# Three-Model Ensemble Configuration
# =============================================================================
BOT_ENABLE_GAP_NOTIFICATIONS=true
BOT_GAP_NOTIFICATION_CHANNEL_ID=your_staff_channel_id_here

# =============================================================================
# ASH NLP SERVICE CONFIGURATION - THREE MODEL ENSEMBLE
# Environment variables for the Enhanced NLP Service v4.3
# Repository: https://github.com/the-alphabet-cartel/ash-nlp
# Part of: The Alphabet Cartel (https://discord.gg/alphabetcartel) Ash Ecosystem
# =============================================================================
# =============================================================================
# HUGGING FACE CONFIGURATION
# =============================================================================
NLP_HUGGINGFACE_CACHE_DIR=./models/cache

# =============================================================================
# LEARNING SYSTEM CONFIGURATION
# =============================================================================
NLP_LEARNING_RATE=0.1
NLP_MAX_LEARNING_ADJUSTMENTS_PER_DAY=50
NLP_LEARNING_PERSISTENCE_FILE=./learning_data/adjustments.json
NLP_MIN_CONFIDENCE_ADJUSTMENT=0.05
NLP_MAX_CONFIDENCE_ADJUSTMENT=0.30

# =============================================================================
# THREE-MODEL CONFIGURATION
# =============================================================================
# Model 1: Primary crisis detection (DeBERTa-based depression analysis)
NLP_DEPRESSION_MODEL=rafalposwiata/deproberta-large-depression

# Model 2: Contextual sentiment analysis (RoBERTa-based sentiment)
# NLP_SENTIMENT_MODEL=cardiffnlp/twitter-roberta-base-sentiment-latest
NLP_SENTIMENT_MODEL=siebert/sentiment-roberta-large-english

# Model 3: Emotional distress detection (DistilBERT-based emotional analysis)
NLP_EMOTIONAL_DISTRESS_MODEL=distilbert-base-uncased-finetuned-sst-2-english

# Model storage configuration
NLP_MODEL_CACHE_DIR=./models/cache

# =============================================================================
# ENSEMBLE CONFIGURATION
# =============================================================================
# Ensemble modes: consensus, majority, weighted
NLP_ENSEMBLE_MODE=consensus

# Gap detection settings
NLP_GAP_DETECTION_THRESHOLD=0.4
NLP_DISAGREEMENT_THRESHOLD=0.5
NLP_AUTO_FLAG_DISAGREEMENTS=true

# Model confidence weighting (for weighted ensemble mode)
NLP_DEPRESSION_MODEL_WEIGHT=0.5
NLP_SENTIMENT_MODEL_WEIGHT=0.2
NLP_EMOTIONAL_DISTRESS_MODEL_WEIGHT=0.3

# =============================================================================
# HARDWARE CONFIGURATION
# =============================================================================
NLP_DEVICE=auto  # auto, cpu, cuda, or specific device like cuda:0
NLP_MODEL_PRECISION=float16  # float32, float16, or bfloat16

# =============================================================================
# PERFORMANCE TUNING - THREE MODEL OPTIMIZATION
# =============================================================================
# Optimized for RTX 3060 (12GB VRAM) + Ryzen 7 5800X + 64GB RAM
NLP_MAX_BATCH_SIZE=32  # Much larger batches with 12GB VRAM
NLP_INFERENCE_THREADS=16  # Ryzen 7 5800X has 8 cores/16 threads
NLP_MAX_CONCURRENT_REQUESTS=20  # Higher with abundant VRAM and RAM
NLP_REQUEST_TIMEOUT=40  # Faster with more VRAM for batch processing

# =============================================================================
# SERVER CONFIGURATION
# =============================================================================
NLP_SERVICE_HOST=0.0.0.0
NLP_SERVICE_PORT=8881
NLP_UVICORN_WORKERS=1
NLP_RELOAD_ON_CHANGES=false

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================
NLP_LOG_FILE=nlp_service.log
NLP_FLIP_SENTIMENT_LOGIC=false

# =============================================================================
# STORAGE PATHS
# =============================================================================
NLP_DATA_DIR=./data
NLP_MODELS_DIR=./models/cache
NLP_LOGS_DIR=./logs
NLP_LEARNING_DATA_DIR=./learning_data

# =============================================================================
# CRISIS DETECTION THRESHOLDS
# =============================================================================
# Individual model thresholds
NLP_HIGH_CRISIS_THRESHOLD=0.55
NLP_MEDIUM_CRISIS_THRESHOLD=0.28
NLP_LOW_CRISIS_THRESHOLD=0.16

# Ensemble-specific thresholds
NLP_ENSEMBLE_HIGH_CRISIS_THRESHOLD=0.60
NLP_ENSEMBLE_MEDIUM_CRISIS_THRESHOLD=0.35
NLP_ENSEMBLE_LOW_CRISIS_THRESHOLD=0.20

# =============================================================================
# RATE LIMITING
# =============================================================================
NLP_MAX_REQUESTS_PER_MINUTE=120  # Much higher with 12GB VRAM + excellent hardware
NLP_MAX_REQUESTS_PER_HOUR=2000   # Significantly increased for abundant VRAM

# =============================================================================
# EXPERIMENTAL FEATURES
# =============================================================================
# Enable experimental three-model features
NLP_ENABLE_ENSEMBLE_ANALYSIS=true
NLP_ENABLE_GAP_DETECTION=true
NLP_ENABLE_CONFIDENCE_SPREADING=true
NLP_LOG_MODEL_DISAGREEMENTS=true

# =============================================================================
# ASH-DASH CONFIGURATION
# =============================================================================
DASH_ENABLE_SSL=false
DASH_SSL_CERT_PATH=/run/secrets/cert.pem
DASH_SSL_KEY_PATH=/run/secrets/key.pem
DASH_BOT_API_TIMEOUT=5000
DASH_NLP_API_TIMEOUT=10000
DASH_CACHE_TTL=600
DASH_ENABLE_SOCKET_IO=true
DASH_METRICS_UPDATE_INTERVAL=60000
DASH_LOG_DIR=./logs
DASH_LOG_FILE=ash-dash.log
DASH_ENABLE_ACCESS_LOGS=true
DASH_RATE_LIMIT_WINDOW=900000
DASH_RATE_LIMIT_MAX=100
DASH_RATE_LIMIT_MESSAGE="Too many requests, please try again later"

# =============================================================================
# ASH-THRASH CONFIGURATION
# =============================================================================
THRASH_MAX_CONCURRENT_TESTS=5
THRASH_API_HOST=0.0.0.0